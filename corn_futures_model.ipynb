{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install fredapi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UNISAdUS0E9",
        "outputId": "60e82e02-e40d-44e5-e340-79eb7b46cbea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fredapi\n",
            "  Downloading fredapi-0.5.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from fredapi) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas->fredapi) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->fredapi) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->fredapi) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->fredapi) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->fredapi) (1.17.0)\n",
            "Downloading fredapi-0.5.2-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: fredapi\n",
            "Successfully installed fredapi-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Yi3RN_K54RAH"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "=============================================================\n",
        "  CORN COMMODITY PRICE PREDICTION â€” ML PIPELINE\n",
        "=============================================================\n",
        "Author: Claude (Anthropic)\n",
        "Description:\n",
        "    End-to-end machine learning pipeline to predict monthly\n",
        "    corn futures prices (CBOT front-month, $/bushel).\n",
        "\n",
        "Data Sources (live API calls are stubbed; swap in your keys):\n",
        "    - USDA NASS Quick Stats API  â†’ acreage, yield, stocks\n",
        "    - USDA WASDE/ERS             â†’ supply/demand balances\n",
        "    - NOAA CDO API               â†’ temperature, precipitation\n",
        "    - EIA API                    â†’ ethanol production, crude oil\n",
        "    - FRED API (St. Louis Fed)   â†’ DXY, interest rates, CPI\n",
        "    - CFTC COT reports           â†’ managed money positioning\n",
        "    - Quandl/Nasdaq Data Link    â†’ corn futures prices\n",
        "\n",
        "Model:\n",
        "    Gradient Boosting Regressor (sklearn) with walk-forward\n",
        "    cross-validation. Predicts next-month corn price.\n",
        "\n",
        "=============================================================\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import requests\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 1.  LIVE DATA FETCHING  (commented stubs â€” add your API keys)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def fetch_usda_nass(api_key, commodity=\"CORN\", year_start=2000, year_end=2025):\n",
        "    \"\"\"\n",
        "    Fetch acreage, yield, and production from USDA NASS Quick Stats.\n",
        "\n",
        "    API docs: https://quickstats.nass.usda.gov/api\n",
        "    Get a free key at: https://quickstats.nass.usda.gov/api#param_define\n",
        "    \"\"\"\n",
        "    url = \"https://quickstats.nass.usda.gov/api/api_GET/\"\n",
        "    params = {\n",
        "        \"key\": api_key,\n",
        "        \"commodity_desc\": commodity,\n",
        "        \"statisticcat_desc\": \"YIELD\",\n",
        "        \"agg_level_desc\": \"NATIONAL\",\n",
        "        \"year__GE\": year_start,\n",
        "        \"format\": \"JSON\"\n",
        "        }\n",
        "    r = requests.get(url, params=params)\n",
        "    data = r.json()[\"data\"]\n",
        "    return pd.DataFrame(data)[[\"year\",\"Value\"]].rename(columns={\"Value\":\"yield_bu_acre\"})\n",
        "\n",
        "\n",
        "def fetch_eia(api_key, series_id=\"PET.RWTC.M\"):\n",
        "    \"\"\"\n",
        "    Fetch EIA time series (crude oil, ethanol production, etc.)\n",
        "\n",
        "    API docs: https://api.eia.gov/bulk/\n",
        "    Series IDs:\n",
        "        PET.RWTC.M       â†’ WTI Crude Oil monthly ($/bbl)\n",
        "        STEO.CORNPROD_US.M â†’ Ethanol production proxy\n",
        "        EIA-AEO.REF2023.COGEN_GEN_NA_GEN_NA_NA_ELC_BLNKWH.A â†’ Ethanol plant capacity\n",
        "    \"\"\"\n",
        "\n",
        "    url = f\"https://api.eia.gov/v2/seriesid/{series_id}\"\n",
        "    r = requests.get(url, params={\"api_key\": api_key, \"frequency\": \"monthly\"})\n",
        "    df = pd.DataFrame(r.json()[\"response\"][\"data\"])\n",
        "    df[\"date\"] = pd.to_datetime(df[\"period\"])\n",
        "    return df.set_index(\"date\")[[\"value\"]].rename(columns={\"value\": series_id})\n",
        "\n",
        "\n",
        "def fetch_fred(api_key, series_ids=(\"DTWEXBGS\", \"FEDFUNDS\", \"CPIAUCSL\")):\n",
        "    \"\"\"\n",
        "    Fetch macroeconomic series from FRED.\n",
        "\n",
        "    API docs: https://fred.stlouisfed.org/docs/api/fred/\n",
        "    Series IDs:\n",
        "        DTWEXBGS  â†’ Nominal Broad Dollar Index (DXY-equivalent)\n",
        "        FEDFUNDS  â†’ Federal Funds Rate\n",
        "        CPIAUCSL  â†’ Consumer Price Index\n",
        "    \"\"\"\n",
        "\n",
        "    from fredapi import Fred\n",
        "    fred = Fred(api_key=api_key)\n",
        "    frames = {sid: fred.get_series(sid, observation_start=\"2000-01-01\")\n",
        "                  for sid in series_ids}\n",
        "    return pd.DataFrame(frames).resample(\"MS\").last()\n",
        "\n",
        "\n",
        "def fetch_cftc_cot():\n",
        "    \"\"\"\n",
        "    Download CFTC Commitments of Traders data for CORN futures.\n",
        "\n",
        "    CFTC publishes bulk CSV files at:\n",
        "    https://www.cftc.gov/MarketReports/CommitmentsofTraders/HistoricalCompressed/index.htm\n",
        "\n",
        "    Example:\n",
        "    \"\"\"\n",
        "    url = \"https://www.cftc.gov/files/dea/history/fut_disagg_txt_hist_2006_2024.zip\"\n",
        "    df = pd.read_csv(url, compression=\"zip\")\n",
        "    corn = df[df[\"Market_and_Exchange_Names\"].str.contains(\"CORN\", na=False)]\n",
        "    corn[\"date\"] = pd.to_datetime(corn[\"As_of_Date_In_Form_YYMMDD\"], format=\"%y%m%d\")\n",
        "    return corn.set_index(\"date\")[[\"M_Money_Positions_Long_All\", \"M_Money_Positions_Short_All\"]]\n",
        "\n",
        "\n",
        "def fetch_noaa_climate(token, station_id=\"GHCND:USW00094846\", start=\"2000-01-01\"):\n",
        "    \"\"\"\n",
        "    Fetch monthly temperature & precipitation from NOAA CDO API.\n",
        "\n",
        "    API docs: https://www.ncdc.noaa.gov/cdo-web/webservices/v2\n",
        "    Get a free token at: https://www.ncdc.noaa.gov/cdo-web/token\n",
        "    \"\"\"\n",
        "    headers = {\"token\": token}\n",
        "    url = \"https://www.ncdc.noaa.gov/cdo-web/api/v2/data\"\n",
        "    params = {\n",
        "        \"datasetid\": \"GSOM\",\n",
        "        \"stationid\": station_id,\n",
        "        \"startdate\": start,\n",
        "        \"enddate\": \"2025-12-31\",\n",
        "        \"datatypeid\": \"TAVG,PRCP\",\n",
        "        \"limit\": 1000\n",
        "        }\n",
        "    r = requests.get(url, headers=headers, params=params)\n",
        "    df = pd.DataFrame(r.json()[\"results\"])\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "\n",
        "    return df.pivot(index=\"date\", columns=\"datatype\", values=\"value\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2.  SYNTHETIC DATA GENERATION\n",
        "#     Mirrors real statistical properties of each source.\n",
        "#     Replace each block with a live fetch call above.\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def generate_synthetic_dataset(start=\"2000-01-01\", end=\"2025-12-31\", seed=42):\n",
        "    \"\"\"\n",
        "    Generate a realistic monthly dataset of corn price drivers.\n",
        "    Statistical properties calibrated to historical USDA/NOAA/EIA data.\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    dates = pd.date_range(start, end, freq=\"MS\")\n",
        "    n = len(dates)\n",
        "    t = np.arange(n)\n",
        "    month = pd.DatetimeIndex(dates).month.to_numpy()\n",
        "\n",
        "    # â”€â”€ Corn price (target): trend + seasonality + shocks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    # Real corn ranged ~$2â€“$8.50/bu from 2000â€“2024\n",
        "    trend       = 2.0 + t * 0.005                                   # slow upward trend\n",
        "    season_p    = 0.3 * np.sin(2 * np.pi * (month - 3) / 12)       # seasonal dip at harvest\n",
        "    shocks      = rng.normal(0, 0.15, n)\n",
        "    shocks[120] += 2.2   # 2010â€“2012 drought spike\n",
        "    shocks[60]  += 0.8   # 2005 ethanol boom\n",
        "    shocks[230] -= 0.6   # 2019 trade war dip\n",
        "    price       = trend + season_p + np.cumsum(shocks * 0.3) + 2.5\n",
        "    price       = np.clip(price, 1.8, 9.0).astype(float)\n",
        "\n",
        "    # â”€â”€ USDA: Yield (bu/acre) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    # National avg ~150â€“185 bu/acre; varies by weather, genetics\n",
        "    base_yield  = 140 + t * 0.18\n",
        "    yield_shock = rng.normal(0, 8, n)\n",
        "    yield_shock[np.where((month == 8) | (month == 9))[0]] += \\\n",
        "        rng.choice([-15, -10, 0, 5], size=np.sum((month == 8) | (month == 9)))\n",
        "    corn_yield  = base_yield + yield_shock\n",
        "    corn_yield  = np.clip(corn_yield, 100, 200)\n",
        "\n",
        "    # â”€â”€ USDA: Planted acreage (million acres) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    base_acres  = 75 + rng.normal(0, 3, n)\n",
        "    # Corn/soy rotation: acreage varies with relative prices\n",
        "    acres_adj   = base_acres + 0.5 * (price - price.mean()) / price.std()\n",
        "    planted_acres = np.clip(acres_adj, 60, 95)\n",
        "\n",
        "    # â”€â”€ USDA: Ending stocks-to-use ratio (%) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    # Low S/U â†’ higher prices. Inversely correlated with price.\n",
        "    stu = 15 - 1.5 * (price - price.mean()) / price.std() + rng.normal(0, 2, n)\n",
        "    stu = np.clip(stu, 3, 35)\n",
        "\n",
        "\n",
        "    # â”€â”€ NOAA: Growing season temp anomaly (Â°C from avg) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    temp_anomaly = rng.normal(0, 0.8, n)\n",
        "    temp_anomaly += 0.015 * t / 12    # warming trend\n",
        "\n",
        "    # â”€â”€ NOAA: Precipitation anomaly (% of normal) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    precip_anomaly = rng.normal(100, 15, n)\n",
        "    # 2012 drought\n",
        "    precip_anomaly[140:155] -= 35\n",
        "\n",
        "\n",
        "    # â”€â”€ EIA: WTI Crude Oil ($/bbl) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    oil_trend  = 30 + t * 0.18\n",
        "    oil_season = 5 * np.sin(2 * np.pi * month / 12)\n",
        "    oil_shock  = np.cumsum(rng.normal(0, 2.5, n))\n",
        "    crude_oil  = np.clip(oil_trend + oil_season + oil_shock * 0.2, 20, 130)\n",
        "\n",
        "    # â”€â”€ EIA: Ethanol production (million gallons/month) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    ethanol = 200 + t * 4.5 + rng.normal(0, 20, n)\n",
        "    ethanol = np.clip(ethanol, 180, 1600)\n",
        "\n",
        "\n",
        "    # â”€â”€ FRED: USD Index (DXY-equivalent, broad) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    usd_index = 110 + np.cumsum(rng.normal(0, 0.5, n)) * 0.3\n",
        "    usd_index = np.clip(usd_index, 85, 135)\n",
        "\n",
        "    # â”€â”€ FRED: Federal Funds Rate (%) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    fed_funds = np.clip(5 - t * 0.015 + rng.normal(0, 0.3, n), 0.05, 8.0)\n",
        "\n",
        "    # â”€â”€ FRED: CPI YoY (%) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    cpi = 2.0 + rng.normal(0, 0.5, n) + np.clip((t - 240) * 0.04, 0, 7)\n",
        "\n",
        "\n",
        "    # â”€â”€ CFTC: Managed Money Net Position (contracts, thousands) â”€â”€â”€â”€â”€\n",
        "    mm_net = 150 + 80 * np.sin(2 * np.pi * t / 36) + rng.normal(0, 30, n)\n",
        "    mm_net += 50 * (price - price.mean()) / price.std()   # momentum effect\n",
        "\n",
        "    # â”€â”€ Soybean/Corn ratio (planting decision signal) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    soy_price   = price * (2.5 + rng.normal(0, 0.2, n))\n",
        "    soy_corn_ratio = soy_price / price\n",
        "\n",
        "    # â”€â”€ Natural gas (fertilizer cost proxy) ($/MMBtu) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    nat_gas = 3.5 + np.cumsum(rng.normal(0, 0.1, n)) * 0.15\n",
        "    nat_gas = np.clip(nat_gas, 1.5, 12.0)\n",
        "\n",
        "    # â”€â”€ Crop progress: % harvested by month â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    harvest_pct = np.where(month == 10, 50,\n",
        "                  np.where(month == 11, 90,\n",
        "                  np.where(month == 12, 98, 5))).astype(float)\n",
        "    harvest_pct += rng.normal(0, 3, n)\n",
        "    harvest_pct = np.clip(harvest_pct, 0, 100)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        \"date\":             dates,\n",
        "        \"corn_price\":       price,          # TARGET ($/bushel)\n",
        "        # USDA\n",
        "        \"yield_bu_acre\":    corn_yield,\n",
        "        \"planted_acres_m\":  planted_acres,\n",
        "        \"stocks_to_use\":    stu,\n",
        "        # NOAA\n",
        "        \"temp_anomaly_c\":   temp_anomaly,\n",
        "        \"precip_pct_normal\":precip_anomaly,\n",
        "        # EIA\n",
        "        \"crude_oil_usd\":    crude_oil,\n",
        "        \"ethanol_prod_mgal\":ethanol,\n",
        "        \"nat_gas_usd\":      nat_gas,\n",
        "        # FRED\n",
        "        \"usd_index\":        usd_index,\n",
        "        \"fed_funds_rate\":   fed_funds,\n",
        "        \"cpi_yoy\":          cpi,\n",
        "        # CFTC\n",
        "        \"mm_net_pos_k\":     mm_net,\n",
        "        # Derived\n",
        "        \"soy_corn_ratio\":   soy_corn_ratio,\n",
        "        \"harvest_pct\":      harvest_pct,\n",
        "        \"month\":            month,\n",
        "    }).set_index(\"date\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2.  REAL DATA COLLECTION\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def collect_real_datasets(start=\"2000-01-01\", end=\"2025-12-31\", seed=42):\n",
        "    \"\"\"\n",
        "    Generate a realistic monthly dataset of corn price drivers.\n",
        "    Statistical properties calibrated to historical USDA/NOAA/EIA data.\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    dates = pd.date_range(start, end, freq=\"MS\")\n",
        "    n = len(dates)\n",
        "    t = np.arange(n)\n",
        "    month = pd.DatetimeIndex(dates).month.to_numpy()\n",
        "\n",
        "    # â”€â”€ Corn price (target): trend + seasonality + shocks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    # Real corn ranged ~$2â€“$8.50/bu from 2000â€“2024\n",
        "    import yfinance as yf\n",
        "\n",
        "    # Load the commodity price data\n",
        "    price_df = yf.download('ZC=F', start=start, end=end, interval='1mo')\n",
        "    price_df.head()\n",
        "\n",
        "    price = price_df[\"Close\"]\n",
        "    #price = np.clip(price, 1.8, 9.0).astype(float)\n",
        "\n",
        "    # â”€â”€ USDA\n",
        "    usda_df = fetch_usda_nass()\n",
        "    usda_df.head()\n",
        "\n",
        "    # â”€â”€ USDA: Yield (bu/acre) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    # National avg ~150â€“185 bu/acre; varies by weather, genetics\n",
        "    corn_yield  = usda_df[\"yield_bu_acre\"]\n",
        "\n",
        "    # â”€â”€ USDA: Planted acreage (million acres) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "\n",
        "    # â”€â”€ USDA: Ending stocks-to-use ratio (%) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "\n",
        "    # â”€â”€ NOAA\n",
        "    #noaa_df = fetch_noaa_climate()\n",
        "    #noaa_df.head()\n",
        "\n",
        "    # â”€â”€ NOAA: Growing season temp anomaly (Â°C from avg) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    #temp_anomaly = noaa_df[\"\"]\n",
        "\n",
        "    # â”€â”€ NOAA: Precipitation anomaly (% of normal) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    #precip_anomaly = noaa_df[\"\"]\n",
        "\n",
        "\n",
        "    # â”€â”€ EIA\n",
        "    eia_df = fetch_eia()\n",
        "    eia_df.head()\n",
        "\n",
        "    # â”€â”€ EIA: WTI Crude Oil ($/bbl) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    crude_oil = eia_df[\"PET.RWTC.M\"]\n",
        "\n",
        "    # â”€â”€ Natural gas (fertilizer cost proxy) ($/MMBtu) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    #nat_gas = fetch_eia(series_id = \"\"\")\n",
        "\n",
        "    # â”€â”€ EIA: Ethanol production (million gallons/month) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    #ethanol_df = fetch_eia(series_id = \"STEO.CORNPROD_US.M\")\n",
        "    #ethanol = ethanol_df[\"STEO.CORNPROD_US.M\"]\n",
        "\n",
        "\n",
        "    # â”€â”€ FRED\n",
        "    fred_df = fetch_fred()\n",
        "    fred_df.head()\n",
        "\n",
        "    # â”€â”€ FRED: USD Index (DXY-equivalent, broad) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    usd_index = fred_df[\"DTWEXBGS\"]\n",
        "\n",
        "    # â”€â”€ FRED: Federal Funds Rate (%) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    fed_funds = fred_df[\"FEDFUNDS\"]\n",
        "\n",
        "    # â”€â”€ FRED: CPI YoY (%) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    cpi = fed_funds = fred_df[\"CPIAUCSL\"]\n",
        "\n",
        "\n",
        "    # â”€â”€ CFTC\n",
        "    #cftc_df = fetch_cftc_cot()\n",
        "    #cftc_df.head()\n",
        "\n",
        "    # â”€â”€ CFTC: Managed Money Net Position (contracts, thousands) â”€â”€â”€â”€â”€\n",
        "    #mn_net = cftc_df[\"\"]\n",
        "\n",
        "\n",
        "    # â”€â”€ Soybean/Corn ratio (planting decision signal) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    soy_price_df = yf.download('ZS=F', start=start, end=end, interval='1mo')\n",
        "    soy_price_df.head()\n",
        "\n",
        "    soy_price = soy_price_df[\"Close\"]\n",
        "    soy_corn_ratio = soy_price / price\n",
        "\n",
        "\n",
        "    # â”€â”€ Crop progress: % harvested by month â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    harvest_pct = np.where(month == 10, 50,\n",
        "                  np.where(month == 11, 90,\n",
        "                  np.where(month == 12, 98, 5))).astype(float)\n",
        "    harvest_pct += rng.normal(0, 3, n)\n",
        "    harvest_pct = np.clip(harvest_pct, 0, 100)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        \"date\":             dates,\n",
        "        \"corn_price\":       price,          # TARGET ($/bushel)\n",
        "        # USDA\n",
        "        \"yield_bu_acre\":    corn_yield,\n",
        "        #\"planted_acres_m\":  planted_acres,\n",
        "        #\"stocks_to_use\":    stu,\n",
        "        # NOAA\n",
        "        #\"temp_anomaly_c\":   temp_anomaly,\n",
        "        #\"precip_pct_normal\":precip_anomaly,\n",
        "        # EIA\n",
        "        \"crude_oil_usd\":    crude_oil,\n",
        "        #\"ethanol_prod_mgal\":ethanol,\n",
        "        #\"nat_gas_usd\":      nat_gas,\n",
        "        # FRED\n",
        "        \"usd_index\":        usd_index,\n",
        "        \"fed_funds_rate\":   fed_funds,\n",
        "        \"cpi_yoy\":          cpi,\n",
        "        # CFTC\n",
        "        #\"mm_net_pos_k\":     mm_net,\n",
        "        # Derived\n",
        "        \"soy_corn_ratio\":   soy_corn_ratio,\n",
        "        \"harvest_pct\":      harvest_pct,\n",
        "        \"month\":            month,\n",
        "    }).set_index(\"date\")\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "g1uClqarRN2O"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 3.  FEATURE ENGINEERING\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Build lag features, rolling statistics, and derived signals.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    base_features = [\"yield_bu_acre\", \"crude_oil_usd\", \"usd_index\", \"fed_funds_rate\", \"cpi_yoy\", \"soy_corn_ratio\", \"harvest_pct\"]#, \"planted_acres_m\", \"stocks_to_use\", \"temp_anomaly_c\", \"precip_pct_normal\", \"ethanol_prod_mgal\", \"nat_gas_usd\", \"mm_net_pos_k\"]\n",
        "\n",
        "    # Lag features: t-1, t-2, t-3, t-6, t-12\n",
        "    for feat in base_features:\n",
        "        for lag in [1, 2, 3, 6, 12]:\n",
        "            df[f\"{feat}_lag{lag}\"] = df[feat].shift(lag)\n",
        "\n",
        "    # Rolling statistics on price (momentum)\n",
        "    for window in [3, 6, 12]:\n",
        "        df[f\"price_ma{window}\"]   = df[\"corn_price\"].shift(1).rolling(window).mean()\n",
        "        df[f\"price_std{window}\"]  = df[\"corn_price\"].shift(1).rolling(window).std()\n",
        "        df[f\"price_mom{window}\"]  = df[\"corn_price\"].shift(1).pct_change(window)\n",
        "\n",
        "    # Rolling stats on key drivers\n",
        "    for feat in [\"crude_oil_usd\", \"mm_net_pos_k\", \"stocks_to_use\"]:\n",
        "        df[f\"{feat}_ma3\"]  = df[feat].shift(1).rolling(3).mean()\n",
        "        df[f\"{feat}_diff1\"] = df[feat].diff(1)\n",
        "\n",
        "    # Calendar: month dummies capture seasonality\n",
        "    for m in range(1, 13):\n",
        "        df[f\"month_{m}\"] = (df[\"month\"] == m).astype(int)\n",
        "\n",
        "    # Interaction: oil Ã— USD (dollar-denominated commodity effect)\n",
        "    df[\"oil_x_usd\"] = df[\"crude_oil_usd_lag1\"] * df[\"usd_index_lag1\"]\n",
        "\n",
        "    # Ratio: stocks-to-use momentum\n",
        "    df[\"stu_chg3\"] = df[\"stocks_to_use\"].diff(3)\n",
        "\n",
        "    # Drop the raw month column (encoded as dummies above)\n",
        "    df = df.drop(columns=[\"month\"])\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "_DhU4g68RSkq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 4.  WALK-FORWARD CROSS-VALIDATION\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def walk_forward_cv(model, X: pd.DataFrame, y: pd.Series,\n",
        "                    min_train_months=60, step=6):\n",
        "    \"\"\"\n",
        "    Time-series walk-forward validation.\n",
        "    Train on expanding window, predict next `step` months.\n",
        "    Returns predictions DataFrame aligned to y's index.\n",
        "    \"\"\"\n",
        "    preds = pd.Series(index=y.index, dtype=float)\n",
        "    indices = np.arange(len(y))\n",
        "\n",
        "    for split in range(min_train_months, len(y) - step + 1, step):\n",
        "        train_idx = indices[:split]\n",
        "        test_idx  = indices[split:split + step]\n",
        "\n",
        "        X_tr, y_tr = X.iloc[train_idx], y.iloc[train_idx]\n",
        "        X_te        = X.iloc[test_idx]\n",
        "\n",
        "        model.fit(X_tr, y_tr)\n",
        "        preds.iloc[test_idx] = model.predict(X_te)\n",
        "\n",
        "    return preds"
      ],
      "metadata": {
        "id": "1tEGZepPRW8H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 5.  MODEL TRAINING & EVALUATION\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def train_and_evaluate(df_feat: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Train three models (Ridge, Random Forest, Gradient Boosting),\n",
        "    run walk-forward CV, compare metrics, pick winner.\n",
        "    \"\"\"\n",
        "    target = \"corn_price\"\n",
        "    feature_cols = [c for c in df_feat.columns if c != target]\n",
        "\n",
        "    df_model = df_feat[[target] + feature_cols].dropna()\n",
        "    y = df_model[target]\n",
        "    X = df_model[feature_cols]\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"  Dataset: {len(X)} months  |  Features: {len(feature_cols)}\")\n",
        "    print(f\"  Date range: {X.index[0].date()} â†’ {X.index[-1].date()}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    models = {\n",
        "        \"Ridge Regression\": Pipeline([\n",
        "            (\"scaler\", StandardScaler()),\n",
        "            (\"model\",  Ridge(alpha=10.0))\n",
        "        ]),\n",
        "        \"Random Forest\": RandomForestRegressor(\n",
        "            n_estimators=200, max_depth=8, min_samples_leaf=5,\n",
        "            random_state=42, n_jobs=-1\n",
        "        ),\n",
        "        \"Gradient Boosting\": GradientBoostingRegressor(\n",
        "            n_estimators=300, max_depth=4, learning_rate=0.05,\n",
        "            subsample=0.8, min_samples_leaf=5, random_state=42\n",
        "        ),\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    all_preds = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f\"  Walk-forward CV: {name}...\")\n",
        "        preds = walk_forward_cv(model, X, y, min_train_months=60, step=6)\n",
        "        valid = preds.dropna()\n",
        "        y_valid = y.loc[valid.index]\n",
        "\n",
        "        mae  = mean_absolute_error(y_valid, valid)\n",
        "        rmse = np.sqrt(mean_squared_error(y_valid, valid))\n",
        "        r2   = r2_score(y_valid, valid)\n",
        "        mape = np.mean(np.abs((y_valid - valid) / y_valid)) * 100\n",
        "\n",
        "        results[name] = {\"MAE\": mae, \"RMSE\": rmse, \"RÂ²\": r2, \"MAPE%\": mape}\n",
        "        all_preds[name] = preds\n",
        "\n",
        "        print(f\"     MAE={mae:.3f}  RMSE={rmse:.3f}  RÂ²={r2:.3f}  MAPE={mape:.1f}%\")\n",
        "\n",
        "    # â”€â”€ Train best model on full data for feature importance â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    best_name = max(results, key=lambda k: results[k][\"RÂ²\"])\n",
        "    print(f\"\\n  Best model: {best_name} (RÂ²={results[best_name]['RÂ²']:.3f})\\n\")\n",
        "\n",
        "    best_model = models[best_name]\n",
        "    best_model.fit(X, y)\n",
        "\n",
        "    return best_model, best_name, results, all_preds, X, y"
      ],
      "metadata": {
        "id": "57Ay7AOrRZ3U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 6.  FEATURE IMPORTANCE\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def get_feature_importance(model, model_name, X, y, top_n=20):\n",
        "    \"\"\"Extract feature importances (works for RF/GB natively, Ridge via permutation).\"\"\"\n",
        "    if hasattr(model, \"feature_importances_\"):\n",
        "        imp = pd.Series(model.feature_importances_, index=X.columns)\n",
        "    elif hasattr(model, \"named_steps\"):\n",
        "        # Pipeline (Ridge)\n",
        "        result = permutation_importance(model, X, y, n_repeats=10,\n",
        "                                        random_state=42, n_jobs=-1)\n",
        "        imp = pd.Series(result.importances_mean, index=X.columns)\n",
        "    else:\n",
        "        result = permutation_importance(model, X, y, n_repeats=10,\n",
        "                                        random_state=42, n_jobs=-1)\n",
        "        imp = pd.Series(result.importances_mean, index=X.columns)\n",
        "\n",
        "    return imp.nlargest(top_n)"
      ],
      "metadata": {
        "id": "-IJGYBPiReWx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 7.  PLOTTING\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def plot_results(df_feat, all_preds, results, feature_imp, best_name, output_path):\n",
        "    \"\"\"Generate a comprehensive 4-panel results figure.\"\"\"\n",
        "    y = df_feat[\"corn_price\"]\n",
        "\n",
        "    fig = plt.figure(figsize=(18, 14), facecolor=\"#0f1117\")\n",
        "    gs  = gridspec.GridSpec(3, 2, figure=fig, hspace=0.45, wspace=0.35)\n",
        "\n",
        "    GOLD  = \"#FFD700\"\n",
        "    GREEN = \"#00C896\"\n",
        "    RED   = \"#FF4B4B\"\n",
        "    BLUE  = \"#4B9FFF\"\n",
        "    BG    = \"#0f1117\"\n",
        "    PANEL = \"#1a1d27\"\n",
        "    TEXT  = \"#E8E8E8\"\n",
        "\n",
        "    plt.rcParams.update({\n",
        "        \"axes.facecolor\": PANEL, \"figure.facecolor\": BG,\n",
        "        \"axes.edgecolor\": \"#333\", \"axes.labelcolor\": TEXT,\n",
        "        \"xtick.color\": TEXT, \"ytick.color\": TEXT,\n",
        "        \"text.color\": TEXT, \"grid.color\": \"#2a2d37\",\n",
        "        \"grid.alpha\": 0.5,\n",
        "    })\n",
        "\n",
        "    # â”€â”€ Panel 1: Actual vs. Predicted (best model) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    ax1 = fig.add_subplot(gs[0, :])\n",
        "    best_preds = all_preds[best_name].dropna()\n",
        "    ax1.plot(y.index, y.values, color=GOLD, linewidth=1.5, label=\"Actual Price\", zorder=3)\n",
        "    ax1.plot(best_preds.index, best_preds.values, color=GREEN,\n",
        "             linewidth=1.5, linestyle=\"--\", label=f\"Predicted ({best_name})\", zorder=3)\n",
        "    ax1.fill_between(best_preds.index, y.loc[best_preds.index], best_preds.values,\n",
        "                     alpha=0.15, color=RED)\n",
        "    ax1.set_title(\"Corn Futures Price â€” Actual vs. Walk-Forward CV Predictions\",\n",
        "                  fontsize=13, fontweight=\"bold\", color=GOLD, pad=10)\n",
        "    ax1.set_ylabel(\"Price ($/bushel)\", fontsize=10)\n",
        "    ax1.legend(loc=\"upper left\", framealpha=0.3, fontsize=9)\n",
        "    ax1.grid(True, axis=\"y\")\n",
        "    # Shade drought period\n",
        "    ax1.axvspan(pd.Timestamp(\"2011-06-01\"), pd.Timestamp(\"2013-01-01\"),\n",
        "                alpha=0.1, color=RED, label=\"2012 Drought\")\n",
        "\n",
        "    # â”€â”€ Panel 2: Model Comparison Bar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    ax2 = fig.add_subplot(gs[1, 0])\n",
        "    metrics_df = pd.DataFrame(results).T\n",
        "    x = np.arange(len(metrics_df))\n",
        "    colors = [GREEN if n == best_name else BLUE for n in metrics_df.index]\n",
        "    bars = ax2.bar(x, metrics_df[\"RÂ²\"], color=colors, width=0.5, alpha=0.85)\n",
        "    ax2.set_xticks(x)\n",
        "    ax2.set_xticklabels([n.replace(\" \", \"\\n\") for n in metrics_df.index], fontsize=8)\n",
        "    ax2.set_ylim(0, 1.0)\n",
        "    ax2.set_title(\"Model RÂ² (Walk-Forward CV)\", fontsize=11, fontweight=\"bold\")\n",
        "    ax2.set_ylabel(\"RÂ²\")\n",
        "    ax2.grid(True, axis=\"y\")\n",
        "    for bar, r2 in zip(bars, metrics_df[\"RÂ²\"]):\n",
        "        ax2.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,\n",
        "                 f\"{r2:.3f}\", ha=\"center\", va=\"bottom\", fontsize=9, color=TEXT)\n",
        "\n",
        "    # Metrics table\n",
        "    tbl_data = [[f\"{v['MAE']:.3f}\", f\"{v['RMSE']:.3f}\", f\"{v['MAPE%']:.1f}%\"]\n",
        "                for v in results.values()]\n",
        "    ax2.table(cellText=tbl_data,\n",
        "              rowLabels=[n.replace(\" \", \"\\n\") for n in results.keys()],\n",
        "              colLabels=[\"MAE\", \"RMSE\", \"MAPE\"],\n",
        "              cellLoc=\"center\", loc=\"bottom\", bbox=[0, -0.55, 1, 0.45])\n",
        "\n",
        "    # â”€â”€ Panel 3: Feature Importance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    ax3 = fig.add_subplot(gs[1, 1])\n",
        "    fi = feature_imp.sort_values()\n",
        "    colors_fi = [GOLD if i >= len(fi) - 5 else BLUE for i in range(len(fi))]\n",
        "    ax3.barh(fi.index, fi.values, color=colors_fi, alpha=0.85)\n",
        "    ax3.set_title(f\"Top {len(fi)} Feature Importances\\n({best_name})\",\n",
        "                  fontsize=11, fontweight=\"bold\")\n",
        "    ax3.set_xlabel(\"Importance Score\")\n",
        "    ax3.tick_params(axis=\"y\", labelsize=7)\n",
        "    ax3.grid(True, axis=\"x\")\n",
        "\n",
        "    # â”€â”€ Panel 4: Residual Analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    ax4 = fig.add_subplot(gs[2, 0])\n",
        "    residuals = y.loc[best_preds.index] - best_preds\n",
        "    ax4.scatter(best_preds, residuals, alpha=0.4, s=15, color=BLUE)\n",
        "    ax4.axhline(0, color=GOLD, linewidth=1.5, linestyle=\"--\")\n",
        "    ax4.set_title(\"Residuals vs. Predicted\", fontsize=11, fontweight=\"bold\")\n",
        "    ax4.set_xlabel(\"Predicted Price ($/bu)\")\n",
        "    ax4.set_ylabel(\"Residual ($/bu)\")\n",
        "    ax4.grid(True)\n",
        "\n",
        "    # â”€â”€ Panel 5: Residual Distribution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    ax5 = fig.add_subplot(gs[2, 1])\n",
        "    ax5.hist(residuals, bins=40, color=BLUE, alpha=0.75, edgecolor=\"#333\")\n",
        "    ax5.axvline(residuals.mean(), color=GOLD, linewidth=2, label=f\"Mean: {residuals.mean():.3f}\")\n",
        "    ax5.axvline(residuals.median(), color=GREEN, linewidth=2,\n",
        "                linestyle=\"--\", label=f\"Median: {residuals.median():.3f}\")\n",
        "    ax5.set_title(\"Residual Distribution\", fontsize=11, fontweight=\"bold\")\n",
        "    ax5.set_xlabel(\"Residual ($/bu)\")\n",
        "    ax5.set_ylabel(\"Frequency\")\n",
        "    ax5.legend(fontsize=9)\n",
        "    ax5.grid(True, axis=\"y\")\n",
        "\n",
        "    fig.suptitle(\"ðŸŒ½  CORN COMMODITY PRICE PREDICTION  |  ML Pipeline Results\",\n",
        "                 fontsize=16, fontweight=\"bold\", color=GOLD, y=0.98)\n",
        "\n",
        "    plt.savefig(output_path, dpi=150, bbox_inches=\"tight\", facecolor=BG)\n",
        "    plt.close()\n",
        "    print(f\"  Plot saved â†’ {output_path}\")"
      ],
      "metadata": {
        "id": "Hn3HS47YRhcP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 8.  FORECASTING\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def forecast_next_n_months(model, df_feat, n_months=6):\n",
        "    \"\"\"\n",
        "    Iteratively forecast the next n months using the trained model.\n",
        "    Each step uses the previous prediction as input for lag features.\n",
        "    \"\"\"\n",
        "    df_copy  = df_feat.copy()\n",
        "    feature_cols = [c for c in df_copy.columns if c != \"corn_price\"]\n",
        "    forecasts = []\n",
        "\n",
        "    for i in range(n_months):\n",
        "        last_row = df_copy[feature_cols].iloc[[-1]].copy()\n",
        "        pred = model.predict(last_row.ffill())[0]\n",
        "\n",
        "        next_date = df_copy.index[-1] + pd.DateOffset(months=1)\n",
        "        new_row = df_copy.iloc[-1].copy()\n",
        "        new_row.name = next_date\n",
        "        new_row[\"corn_price\"] = pred\n",
        "\n",
        "        # Shift lag features forward one step\n",
        "        for feat in [c for c in df_copy.columns\n",
        "                     if not c.startswith(\"month_\") and c != \"corn_price\"\n",
        "                     and not any(x in c for x in [\"_lag\", \"_ma\", \"_std\", \"_mom\"])]:\n",
        "            if f\"{feat}_lag1\" in df_copy.columns:\n",
        "                new_row[f\"{feat}_lag1\"] = df_copy[feat].iloc[-1]\n",
        "            if f\"{feat}_lag2\" in df_copy.columns:\n",
        "                new_row[f\"{feat}_lag2\"] = df_copy[f\"{feat}_lag1\"].iloc[-1]\n",
        "            if f\"{feat}_lag3\" in df_copy.columns:\n",
        "                new_row[f\"{feat}_lag3\"] = df_copy[f\"{feat}_lag2\"].iloc[-1]\n",
        "\n",
        "        df_copy = pd.concat([df_copy, pd.DataFrame([new_row])])\n",
        "        forecasts.append({\"date\": next_date, \"forecast_price\": round(pred, 4)})\n",
        "\n",
        "    return pd.DataFrame(forecasts).set_index(\"date\")"
      ],
      "metadata": {
        "id": "B1rRMgU6RjOU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 9.  MAIN\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def main():\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"  ðŸŒ½  CORN PRICE PREDICTION ML PIPELINE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # â”€â”€ Step 1: Load data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    print(\"\\n[1/5]  Generating dataset...\")\n",
        "    df_raw = collect_real_datasets()\n",
        "    print(f\"       {len(df_raw)} monthly observations, {df_raw.shape[1]} raw features\")\n",
        "\n",
        "    # â”€â”€ Step 2: Feature engineering â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    print(\"\\n[2/5]  Engineering features...\")\n",
        "    df_feat = engineer_features(df_raw)\n",
        "    print(f\"       {df_feat.shape[1]} total features after lags/rolling stats\")\n",
        "\n",
        "    # â”€â”€ Step 3: Train & evaluate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    print(\"\\n[3/5]  Training models (walk-forward CV)...\")\n",
        "    best_model, best_name, results, all_preds, X, y = train_and_evaluate(df_feat)\n",
        "\n",
        "    # â”€â”€ Step 4: Feature importance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    print(f\"\\n[4/5]  Computing feature importances ({best_name})...\")\n",
        "    feature_imp = get_feature_importance(best_model, best_name, X, y, top_n=20)\n",
        "    print(\"\\n  Top 10 most predictive features:\")\n",
        "    for feat, score in feature_imp.head(10).items():\n",
        "        print(f\"     {feat:<40} {score:.4f}\")\n",
        "\n",
        "    # â”€â”€ Step 5: Plot & forecast â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    print(\"\\n[5/5]  Generating plots and 6-month forecast...\")\n",
        "    plot_results(df_feat.dropna(), all_preds, results, feature_imp, best_name,\n",
        "                 \"/mnt/user-data/outputs/corn_price_model_results.png\")\n",
        "\n",
        "    forecast_df = forecast_next_n_months(best_model, df_feat.dropna(), n_months=6)\n",
        "    print(\"\\n  ðŸ“ˆ  6-Month Corn Price Forecast ($/bushel):\")\n",
        "    print(\"  \" + \"-\"*35)\n",
        "    for date, row in forecast_df.iterrows():\n",
        "        print(f\"     {date.strftime('%b %Y')}:  ${row['forecast_price']:.2f}/bu\")\n",
        "    print(\"  \" + \"-\"*35)\n",
        "\n",
        "    # â”€â”€ Save results to CSV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    forecast_df.to_csv(\"/mnt/user-data/outputs/corn_price_forecast.csv\")\n",
        "\n",
        "    # Save model metrics\n",
        "    pd.DataFrame(results).T.round(4).to_csv(\n",
        "        \"/mnt/user-data/outputs/corn_model_metrics.csv\")\n",
        "\n",
        "    print(\"\\n  âœ…  Pipeline complete. Outputs saved to /mnt/user-data/outputs/\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PKqrHe01RldT",
        "outputId": "0db58cd8-c882-4439-fd23-70d646ff94a2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "  ðŸŒ½  CORN PRICE PREDICTION ML PIPELINE\n",
            "============================================================\n",
            "\n",
            "[1/5]  Generating dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "array length 312 does not match index length 680",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-641/158882034.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-641/158882034.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# â”€â”€ Step 1: Load data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n[1/5]  Generating dataset...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdf_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_real_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"       {len(df_raw)} monthly observations, {df_raw.shape[1]} raw features\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-641/3093718237.py\u001b[0m in \u001b[0;36mcollect_real_datasets\u001b[0;34m(start, end, seed)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0mharvest_pct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mharvest_pct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     df = pd.DataFrame({\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0;34m\"date\"\u001b[0m\u001b[0;34m:\u001b[0m             \u001b[0mdates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;34m\"corn_price\"\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0mprice\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;31m# TARGET ($/bushel)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    688\u001b[0m                     \u001b[0;34mf\"length {len(index)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 )\n\u001b[0;32m--> 690\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: array length 312 does not match index length 680"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i8VktCuQVZLq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}